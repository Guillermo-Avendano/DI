####################################################
# Index Update Service - main configuration file
#
# Copyright (c) 1983-2023 Rocket Software, Inc. or its affiliates. All Rights Reserved.
#
# Version 10.01.001
#
####################################################


## ========================= ##
## Rochade server connection ##
## ========================= ##

# ------------------------------------------------------------------------------------------------
# Value: The host name of the Rochade server.
# Type of value: String.
# Key is mandatory: Yes.
# ------------------------------------------------------------------------------------------------
hostName=<DI_SERVER_HOST>

# ------------------------------------------------------------------------------------------------
# Value: The port number of the Rochade server.
# Type of value: Integer.
# Key is mandatory: Yes.
# ------------------------------------------------------------------------------------------------
portNumber=8888

# ------------------------------------------------------------------------------------------------
# The Java keystore parameter (tlsCaCertFileJava) specifies where the client can find the certificate of the trusted root CA. These are the available values for the parameter:
# 	* file_name - A Java KeyStore file
# 	* JVM - The certificate store of the JVM
# 	* WIN - Windows only. The Windows certificate store.
# The parameter is used if Transport Layer Security (TLS) is enabled.
# 
# Type of value: String.
# Key is mandatory: No (except if using TLS connection).
# ------------------------------------------------------------------------------------------------
tlsCaCertFileJava=

# ------------------------------------------------------------------------------------------------
# Database
# Value: The name of the Rochade database.
# Type of value: String.
# Key is mandatory: Yes.
# ------------------------------------------------------------------------------------------------
databaseName=AP-DATA

# ------------------------------------------------------------------------------------------------
# empty user will enable the remote user access mode (remote user will need to provide credentials)
# a user must be set when trusted=false
# ------------------------------------------------------------------------------------------------
user=IS-IDX-Update

# ------------------------------------------------------------------------------------------------
# Password for the user account
# or specify trusted=true if you want to use the trusted connection feature of Rochade
# or keep this empty with trusted=false then Account Utilility will be used to retrieve the live password
# ------------------------------------------------------------------------------------------------
password=

# ------------------------------------------------------------------------------------------------
# Enable trusted connection by defining the setting 'trusted' to 'true'.
# Note: You must enable trusted connections on both the Rochade and the application server side
# 
# The file containing the private key must be found in the classpath of the application.
# Best way is to create a file named '.privatekey' with that key and drop it:
# - in the /lib folder (next to the jar files)
# - or next to the script running the tool (IndexUpdater.cmd or IndexUpdater.sh)
# ------------------------------------------------------------------------------------------------
trusted=true

# ------------------------------------------------------------------------------------------------
# AccountUtility
# This application may fetch password automatically from the Account Utility tool.
# When contacting the AccountUtility, this application does the request using the following settings:
# - username (above) for 'user' parameter: is the user specified above (this is the user for which we want to retrieve the password)
# - accountUtility.application for 'application' parameter: The name of the application to specify with '-n' option when fetching password from AccountUtility API. This value specifies how this tool introduces itself near the AccountUtility. Keep this setting empty if not specifying application when adding user to the AccountUtility.
# - accountUtility.accountFile for 'account file' parameter: the file to be used (the one that stores the passwords). It is the file specified with '-f' option the AccountUtility tool. Keep this setting empty to use the default account file.
# ------------------------------------------------------------------------------------------------
accountUtility.application=
accountUtility.accountFile=

# ------------------------------------------------------------------------------------------------
# Value: The name of the Rochade application.
# Type of value: String.
# Key is mandatory: Yes.
# ------------------------------------------------------------------------------------------------
applicationName=METAAPPS

# ------------------------------------------------------------------------------------------------
# Value: The version of the Rochade application.
# Type of value: String.
# Key is mandatory: Yes.
# ------------------------------------------------------------------------------------------------
applicationVersion=PRODUCTION

# ------------------------------------------------------------------------------------------------
# Control Area.
# Define exactly one control space, that is used to manage indexing preferences.
# Values should be the same as in the 'startup.properties' file of the Rochade Browser.
# (so the indexing preferences are correctly shared).
# ------------------------------------------------------------------------------------------------
control.databaseName=AP-DATA
control.applicationName=METABILITY
control.applicationVersion=USER
control.applicationType=MC


## ========================= ##
## Rochade Application pool  ##
## ========================= ##

# ------------------------------------------------------------------------------------------------
# Define if non-pooled plain connections (false, default) or Pooled connections (true) must be used to connect to Rochade
# Type of value: boolean
# Key is mandatory: false
# Default value: false (including if setting is not present or not assigned)
# ------------------------------------------------------------------------------------------------
usePooledConnections=false

# ------------------------------------------------------------------------------------------------
# Value: The maximum number of application objects allowed.
# When using pooled connections: it applies to one pool and the allowed range is between 1 and 100.
# When using non-pooled plain connections: it limits the number of parallel connections created at the same time. The range is unlimited (but above 100 is not reasonable).
# In both cases (pooled or plain connections), since the indexing puts high stress on the Rochade server it is recommended not to go above 30.
# Take care that, if the 'indexing.parallel.cores.oneApplicationPoolPerCore' setting is 'true', then in practice this value is multiplied
# by the value of 'indexing.parallel.cores.maxParallelism' setting what may put too much stress on Rochade server.
# As a rule of thumb, the final number of parallel connections (so once multiplied by the number of cores indexed in parallel) to the Rochade server
# should not exceed 30 for best performance.
# Type of value: Integer.
# Key is mandatory: Yes.
# ------------------------------------------------------------------------------------------------
maxCountApplications=15

# ------------------------------------------------------------------------------------------------
# Value: The maximum number of applications to be kept in the pool forever, even if no bindApplication request occurred for 
# unlimited time. The allowed range is between 0 and the value of the key {@link #maxCountApplicationsKey}. The default value for this key is 0.
# Type of value: Integer.
# Key is mandatory: No.
# ------------------------------------------------------------------------------------------------
#maxCountKeepAlive=2

# ------------------------------------------------------------------------------------------------
# Value: The time in milliseconds to reduce the difference between the number of unused applications in the pool and the optimum number of unused applications 
# by 70%. The allowed range is between 10,000 and 3,600,000 (10 seconds and 1 hour). The default is 300,000 (5 minutes).
# Type of value: Long.
# Key is mandatory: No.
# ------------------------------------------------------------------------------------------------
decayTime=10000

# ------------------------------------------------------------------------------------------------
# Value: The time in milliseconds that an application object may live. If the specified life time
# is exceeded for an application object, the pool disposes it.
# If the object is bound, the pool postpones the disposal until it is released to the pool.
# Type of value: Long.
# Key is mandatory: No. By default the life time of application objects is not limited.
# Valid values: The minimum value is 600,000 milliseconds, the maximum value is not limited. 
# ------------------------------------------------------------------------------------------------
maxLifeTime=6000001

# ------------------------------------------------------------------------------------------------
# Value: The maximum time in milliseconds an application (e.g. a servlet) may use an application object until it is
# obliged to release it to the pool again. If the application exceeds this corresponding value, the pool disposes the application
# object.
# The allowed range is between 100 and 6,000,000 (100 milliseconds and 10 minutes). The default is 300,000 (5 minutes).
# Type of value: Long.
# Key is mandatory: No.
# ------------------------------------------------------------------------------------------------
maxReserveTime=300000

# ------------------------------------------------------------------------------------------------
# Value: The maximum time in milliseconds the pool may be left suspended. If the corresponding value is exceeded
# the pool terminates the suspended state itself.
# The allowed range is between 600,000 and 36,000,000 (10 minutes and 10 hours). The default is 3,600,000 (1 hour).
# Type of value: Long.
# Key is mandatory: No.
# ------------------------------------------------------------------------------------------------
maxSuspendTime=600000

# ------------------------------------------------------------------------------------------------
# Value: The user must return the object to the pool by calling PooledApplication.release() within the time specified in the pool property "maxReserveTime" (default: 300 seconds). 
# If the time limit is exceeded, the pool disposes the application object so that it can no longer be used.
# Type of value: Long.
# Key is mandatory: No.
# ------------------------------------------------------------------------------------------------
maxWaitTime=60000


## ========================= ##
## Solr server connection    ##
## ========================= ##

# ------------------------------------------------------------------------------------------------
# Solr server URL.
# Type of value: URL
# Key is mandatory: Yes
# Example: http://localhost:8181/solr/
# ------------------------------------------------------------------------------------------------
httpSolrServer=http\://<DI_SOLR_HOST>\:8983/solr/

# ------------------------------------------------------------------------------------------------
# Active Index Search Applications 
# Defines which index search applications are active (and so can be searched within and then which need to be indexed).
# Type of value: space or comma separated list of identifiers
# Key is mandatory: Yes
# Supported identifiers: search_mg search_rdb search_rm search_ref search_rds search_rdi search_rbi search_rbd search_rdq search_sti
# ------------------------------------------------------------------------------------------------
index.applications=search_mg search_rdb search_rm search_ref search_rds search_rdi search_rbi search_rbd search_rdq search_sti

# ------------------------------------------------------------------------------------------------
# Maps the Index Search Applications to their respective Solr core.
# Type of value: Solr core name
# Key is mandatory: Yes (but only required for active applications to index)
# ------------------------------------------------------------------------------------------------
search_mg.core=BusinessTermView
search_rdb.core=DWRView
search_rm.core=Models
search_ref.core=ReferenceData
search_rds.core=DataStructure
search_rdi.core=DataIntegration
search_rbi.core=BusinessIntelligence
search_rbd.core=BigData
search_rdq.core=DataQualityManagement
search_sti.core=Stitching

# ------------------------------------------------------------------------------------------------
# Maps the Index Search Applications to their respective configuration file.
# Each configuration file defines, for the corresponding metaApp, what types and attributes must be indexed.
# Type of value: Filename
# Key is mandatory: Yes (but only required for active applications to index). If empty or missing, default file name will be used with the following generation rule: 'xxx' app_id -> 'indexingRules_xxx.properties' configuration file.
# ------------------------------------------------------------------------------------------------
search_mg.conf=indexingRules_mg.properties
search_rdb.conf=indexingRules_rdb.properties
search_rm.conf=indexingRules_rm.properties
search_ref.conf=indexingRules_ref.properties
search_rds.conf=indexingRules_rds.properties
search_rdi.conf=indexingRules_rdi.properties
search_rbi.conf=indexingRules_rbi.properties
search_rbd.conf=indexingRules_rbd.properties
search_rdq.conf=indexingRules_rdq.properties
search_sti.conf=indexingRules_sti.properties

# ------------------------------------------------------------------------------------------------
# Defines times where the suggester rebuild should not be running for this application.
#
# You can specify an optional day or day range between 1 and 7 (e.g.: 1-5 or 5-7 or 7)
# and an optional time range in 24 hours format between 00:00 and 24:00 (e.g.: 06:00-18:00).
# Day numbering follows the ISO-8601 convention: 1 = Monday, 2 = Tuesday, ... 7 = Sunday.
# If the day range is missing, the setting is applied to all days.
# If the start time is missing, 00:00 is assumed, if the end time is missing, 24:00 is assumed.
# Start day must be equal or before end day (day ranges crossing the week boundary are not allowed).
# Start time must be earlier than end time (time ranges crossing midnight are not allowed).
# To suit advanced needs, more that one date-time range can be defined, separating them with a comma
# (e.g.: 6-7#22:00-24:00,6-7#00:00-06:00 or 7#22:00-24:00,1#00:00-06:00).
#
#
# Samples:
#
# disable rebuilds from Monday to Friday:
# search_rdb.suggester.noRebuild=1-5#
#
# disable rebuilds during office hours:
# search_rdb.suggester.noRebuild=1-5#07:30-18:30
#
# disable rebuilds during night hours over weekends:
# search_rdb.suggester.noRebuild=6-7#22:00-24:00,6-7#00:00-06:00
#
# disable rebuilds during night between Saturday and Sunday:
# search_rdb.suggester.noRebuild=6#22:00-,7#-06:00
#
# disable rebuilds during office hours and specific other times (e.g. when scanner imports are running)
# search_rdb.suggester.noRebuild=1-5#08:00-18:00,2#01:00-05:00,6#08:00-12:00,7#13:00-20:00
# ------------------------------------------------------------------------------------------------
#search_mg.suggester.noRebuild=1-5#06:00-20:00
#search_rdb.suggester.noRebuild=1-5#06:00-20:00
#search_rm.suggester.noRebuild=1-5#06:00-20:00
#search_ref.suggester.noRebuild=1-5#06:00-20:00
#search_rds.suggester.noRebuild=1-5#06:00-20:00
#search_rdi.suggester.noRebuild=1-5#06:00-20:00
#search_rbi.suggester.noRebuild=1-5#06:00-20:00
#search_rbd.suggester.noRebuild=1-5#06:00-20:00
#search_rdq.suggester.noRebuild=1-5#06:00-20:00
#search_sti.suggester.noRebuild=1-5#06:00-20:00

# ------------------------------------------------------------------------------------------------
# Provide the configuration file for the Solr boosting
# Type of value: Filename
# Key is mandatory: Yes. If empty or missing, default file name will be used ('boosting.properties').
# ------------------------------------------------------------------------------------------------
solr.boosting.conf=solrBoosting.properties

# ------------------------------------------------------------------------------------------------
# Defines the fields to sort by when items have same matching score (it allows to define a total order for matching items).
# Take care that the main decision-maker for sorting is the matching score which is governed by the boosting of Query Fields (qf).
# The boosting is managed:
# - first into the search preferences (MTB_PREFERENCE items in Rochade db)
# - or secondly, as a backup, default initial values are managed into the indexing rules files (indexingRules_xxx.properties).
#
# Default Value: NAME asc,DEFINITION asc
#
# ------------------------------------------------------------------------------------------------
sort=NAME asc,DEFINITION asc


## ========================= ##
## Advanced settings         ##
## ========================= ##

# ------------------------------------------------------------------------------------------------
# Define if the indexing must reset the base search preferences ("INDEX_BASIC" MTB_PREFERENCE item into S|METABILITY|USER) to its default values.
# The base search preferences are used to provide a value for any search preference that:
# - is not overridden by the shared common preferences (INDEX_SEARCH_xxx MTB_PREFERENCE items into S|METABILITY|USER)
# - is not overridden by the user into the user preference item (MTB_PREFERENCE) of its Portfolio item (MTB_PORTFOLIO).
#
# If set to 'true':
# - the base preference item ("INDEX_BASIC" MTB_PREFERENCE item into S|METABILITY|USER) will be reset to its default values.
# 
# Note: it is MANDATORY to keep this setting to 'false' at all times!
# The only appropriate moment to turn this switch to 'true' is right after an upgrade of the SearchApps from a previous release.
# At that time, it may be salutary to run once a full fresh re-indexing with this setting to 'true' then returning it to 'false' right after.
# Take care that it will remove any existing customization to the search preferences (what is the intended goal), so the customizations
# of the search preferences will need to be done again.
# 
# Type of value: Boolean
# Key is mandatory: No
# Default value: false (including if setting is not present or not assigned)
# ------------------------------------------------------------------------------------------------
resetBaseSearchPreferences=false

# ------------------------------------------------------------------------------------------------
# Define if the indexing must reset the shared search preferences ("INDEX_SEARCH_xxx" MTB_PREFERENCE items into S|METABILITY|USER) to their default values.
# The shared search preferences are used to provide, core by core, a value for any search preference that:
# - is not overridden by the user into the user preference item (MTB_PREFERENCE) of its Portfolio item (MTB_PORTFOLIO).
#
# If set to 'true':
# 	- all the shared preference items shared among all users ("INDEX_SEARCH_xxx" MTB_PREFERENCE items into S|METABILITY|USER) corresponding to the currently indexed core(s) will be reset to its default value.
# 
# Note: it is MANDATORY to keep this setting to 'false' at all times!
# The only appropriate moment to turn this switch to 'true' is right after an upgrade of the SearchApps from a previous release.
# At that time, it may be salutary to run once a full fresh re-indexing with this setting to 'true' then returning it to 'false' right after.
# Take care that it will remove any existing customization to the search preferences (what is the intended goal), so the customizations
# of the search preferences will need to be done again.
# 
# Type of value: Boolean
# Key is mandatory: No
# Default value: false (including if setting is not present or not assigned)
# ------------------------------------------------------------------------------------------------
resetSharedSearchPreferences=false

# ------------------------------------------------------------------------------------------------
# Define if the indexing must reset the custom search preferences of users
# (default value for this setting is 'false' if setting is not present or not assigned).
# 
# If set to 'true':
# 	- the user preference item (MTB_PREFERENCE) corresponding to the currently indexed core(s) will be deleted for each of the user Portfolio (MTB_PORTFOLIO)
# 
# Note: it is greatly recommended to keep this setting to 'false', except if user search preferences are found desynchronized with indexed attributes;
# then it may be salutary to run once a full fresh re-indexing with this setting to 'true' then returning it to 'false'.
# 
# Type of value: Boolean
# Key is mandatory: No
# Default value: false (including if setting is not present or not assigned)
# ------------------------------------------------------------------------------------------------
resetUserSearchPreferences=false

# ------------------------------------------------------------------------------------------------
# undocumented, intentionally 
# ------------------------------------------------------------------------------------------------
visibility.filter=scope\:RWF__GOVERNED_ITEM MG_RBG/GLOSSARY MG_RBG/CONTEXT BPK_CONTEXT MDM_DATA_CONTEXT RWF/WIPTRX_CONTEXT

# ------------------------------------------------------------------------------------------------
# Flag indicating if the report about indexing rules must also display the types that will not be indexed (due to defined indexing rules)
# Type of value: boolean
# Key is mandatory: No
# Default value: false
# ------------------------------------------------------------------------------------------------
IndexUpdater.displayTypesNotToBeIndexedInMergedRulesReport=false

# ------------------------------------------------------------------------------------------------
# Flag indicating if the report about indexing rules must display the type that originally defined the indexing rule (when that rule is inherited by another type)
# Type of value: boolean
# Key is mandatory: No
# Default value: false
# ------------------------------------------------------------------------------------------------
IndexUpdater.displayRuleOriginInMergedRulesReport=false

# ------------------------------------------------------------------------------------------------
# Flag indicating if the report about indexing rules must also display the negative rules
# A negative rule is a rule that cancels the propagation to sub-types of the indexing rule that generated the indexing of same field)
# Type of value: boolean
# Key is mandatory: No
# Default value: false
# ------------------------------------------------------------------------------------------------
IndexUpdater.displayNegativeRulesInMergedRulesReport=false

# ------------------------------------------------------------------------------------------------
# Defines how many items to process are stored at maximum in memory.
# Beyond that value, all the items to process are stored on disk.
# Zero value means always store on disk. Negative value means always store in memory.
# Type of value: integer
# Key is mandatory: No
# Default value: 100000
# ------------------------------------------------------------------------------------------------
storageShiftingSize=100000

# ------------------------------------------------------------------------------------------------
# Define how much Rochade items to count at once from Rochade server
# A zero or negative value means unlimited (all or as many items as possible are counted at once from Rochade).
# CAUTION: Unlimited configuration is STRONGLY DISCOURAGED for this setting!
# Type of value: integer
# Key is mandatory: No
# Default value: 12500
# ------------------------------------------------------------------------------------------------
indexing.counting.chunkSize=12500

# ------------------------------------------------------------------------------------------------
# Define how many items to query at once from Rochade server
# A zero or negative value means unlimited (all or as many items as possible are queried at once from Rochade).
# CAUTION: Unlimited configuration is STRONGLY DISCOURAGED for this setting!
# Type of value: integer
# Key is mandatory: No
# Default value: 12500
# ------------------------------------------------------------------------------------------------
indexing.querying.chunkSize=12500

# ------------------------------------------------------------------------------------------------
# Define how many changed items to process at once
# (best effort is done to obey the limit but may not be 100% respected)
# In other words: It defines the size of chunk of items of same type to handle at once.
# This setting is essential when enabling the parallel indexing of chunk of items.
# Using the same value as 'indexing.querying.chunkSize' setting is generally the best suitable value.
# A zero or negative value means unlimited (all changed items of a given type are processed together).
# CAUTION: Unlimited configuration is STRONGLY DISCOURAGED for this setting!
# Type of value: integer
# Key is mandatory: No
# Default value: 12500
# ------------------------------------------------------------------------------------------------
indexing.processing.chunkSize=12500

# ------------------------------------------------------------------------------------------------
# Specify how much time must elapse before to log again a message that has already been logged.
# Some log entries may be very repetitive, especially when indexing in parallel and the pool size is smaller than the parallelizing level.
# This setting allows to reduce the number of repetitions for such log entries.
# Two identical log entries are not output except if, at least, the time (in milliseconds) specified by this setting
# has elapsed since the previous output of the identical log entry.
# Note that this setting does not apply to each log entries but only to the ones that are internally classified as being very repetitive.
# Type of value: long (time in milliseconds)
# Key is mandatory: No
# Default value: 600000 (10 minutes)
# ------------------------------------------------------------------------------------------------
logging.repetitive.delayInMs=600000

# ------------------------------------------------------------------------------------------------
# Specify how often the log file dedicated to progression must be refreshed.
# After the specified interval (in seconds), the progress log is erased and refreshed with current progression state.
# Type of value: integer
# Key is mandatory: No
# Default value: 10 (10 seconds)
# ------------------------------------------------------------------------------------------------
progressRefreshTime=10

# ------------------------------------------------------------------------------------------------
# Flag indicating if the Solr cores must be indexed in parallel (true) or sequentially (false)
# Type of value: boolean
# Key is mandatory: No
# Default value: true
# ------------------------------------------------------------------------------------------------
indexing.parallel.cores=true

# ------------------------------------------------------------------------------------------------
# This setting has only meaning if 'indexing.parallel.cores' setting is true (otherwise this setting is simply ignored). 
# Specify how many cores are allowed at most to be indexed concurrently (applies only when indexing of cores in parallel is enabled)
# A zero or negative value means unlimited (as many cores as possible are then indexed in parallel with respect to other settings like the size of the application pool)
# CAUTION: Unlimited configuration is STRONGLY DISCOURAGED for this setting!
# Type of value: integer
# Key is mandatory: No
# Default value: 2
# ------------------------------------------------------------------------------------------------
indexing.parallel.cores.maxParallelism=2

# ------------------------------------------------------------------------------------------------
# This setting has only meaning if 'indexing.parallel.cores' setting is true (otherwise this setting is simply ignored).
# However, this setting applies no matter if pooled or plain connections are used (so no matter the value of the 'usePooledConnections' setting).
# Flag indicating if the indexing of each core must use its own private application pool (applies only when indexing of cores in parallel is enabled)
# If false, one unique application pool is shared among the whole indexing service. It limits the maximum parallelism to the size of the application pool
# (what makes more manageable the stress that is applied on the Rochade server).
# If true, multiple application pools are created (at the maximum, it is the number of cores to index in parallel) what increases the stress applied on the Rochade server
# but may enhance the indexing throughput (as far as the Rochade server is not overwhelmed).
# It is recommended to keep the value of the application pool size (maxCountApplications) quite low (5 to 15) when this setting is true.
#
# Type of value: boolean
# Key is mandatory: No
# Default value: true
# ------------------------------------------------------------------------------------------------
indexing.parallel.cores.oneApplicationPoolPerCore=true

# ------------------------------------------------------------------------------------------------
# Flag indicating if the types (to index into the same Solr core) must be indexed in parallel (true) or sequentially (false)
# Type of value: boolean
# Key is mandatory: No
# Default value: true
# ------------------------------------------------------------------------------------------------
indexing.parallel.types=true

# ------------------------------------------------------------------------------------------------
# Specify how many types are allowed at most to be indexed concurrently (applies only when parallel indexing of types is enabled)
# A zero or negative value means unlimited (as many types as possible are then indexed in parallel with respect to other settings like the size of the application pool)
# CAUTION: Unlimited configuration is STRONGLY DISCOURAGED for this setting!
# Type of value: integer
# Key is mandatory: No
# Default value: 3
# ------------------------------------------------------------------------------------------------
indexing.parallel.types.maxParallelism=3

# ------------------------------------------------------------------------------------------------
# Flag indicating if the chunk of items of same type (to index into the same Solr core) must be indexed in parallel (true) or sequentially (false)
# Type of value: boolean
# Key is mandatory: No
# Default value: true
# ------------------------------------------------------------------------------------------------
indexing.parallel.chunks=true

# ------------------------------------------------------------------------------------------------
# Specify how many chunks of one specific type are allowed at most to be indexed concurrently (applies only when parallel indexing of chunks is enabled)
# A zero or negative value means unlimited (as many chunks as possible are then indexed in parallel with respect to other settings like the size of the application pool).
# CAUTION: Unlimited configuration is STRONGLY DISCOURAGED for this setting!
# Type of value: integer
# Key is mandatory: No
# Default value: 5
# ------------------------------------------------------------------------------------------------
indexing.parallel.chunks.maxParallelism=5

# ------------------------------------------------------------------------------------------------
# Indicates if, near the end of indexing, the connections that are freed (because there is no more job at some tasks and associated workers become unemployed)
# must be re-assigned to new workers at other task levels.
# CAUTION: this is a very sensitive setting. Additional workers on resting tasks may help to finish faster
# BUT those extra workers focused on the same area (in practice: items of same type) can also create additional congestion in Rochade server what, at end, lead to finish later.
# TAKE CARE: currently, it is NOT recommended to turn this setting to 'true'.
# Type of value: boolean
# Key is mandatory: No
# Default value: false (currently, it is NOT recommended to turn this setting to 'true')
# ------------------------------------------------------------------------------------------------
indexing.parallel.recycleConnections=false


## ========================= ##
## Solr pushing settings     ##
## ========================= ##

# ------------------------------------------------------------------------------------------------
# Max weight (in MegaBytes) of Solr documents to commit at once.
# In practice it is a boundary that will trigger the automatic commit of all Solr documents that have been generated for indexing and are waiting to be committed.
# In other words, it is the buffer size for data to be committed into Solr core.
# Note that best effort is done to obey the limit but it may not be 100% respected (effective commit size may be some percents above that limit).
# Note: if 'indexing.solr.docsChunkCommitImmediately' is set to 'true', this setting is ignored because Solr documents are not buffered but committed as soon as they are ready.
# 
# Important: This value must be adapted according to the max available memory allocated to the application. The more memory, the bigger this value can be.
# 
# Type of value: float (in MegaBytes)
# Key is mandatory: No (but highly recommended)
# Default value: 20
# ------------------------------------------------------------------------------------------------
indexing.solr.docsChunkMaxWeightInMB=20

# ------------------------------------------------------------------------------------------------
# Flag influencing when Solr documents are committed
# - if 'true' then a commit happens as soon as a batch of documents is processed and ready to be pushed into Solr (the batch size is determined by the chunk size of new updates that the IndexUpdater provides to the Solr update handler). In other words, the Solr update handler does not maintain its own batch size but align it with the chunk size configured for the IndexUpdater.
# 		When this flag is 'true', the 'indexing.solr.docsChunkMaxWeightInMB' setting is ignored.
# - if 'false' then a commit happens only once the 'indexing.solr.docsChunkMaxWeightInMB' value has been reached for the batch size. In this case, this Solr update handler maintains its own batch size. Note that this batch size is not determined by the number of documents but by the total byte size of the batch.
# 		If 'indexing.solr.docsChunkMaxWeightInMB' is not defined or is zero or negative, a commit happens only when the IndexUpdater does an explicit commit (what occurs once all items of a given type are processed)!
#
# Type of value: boolean
# Key is mandatory: No
# Default value: false
# ------------------------------------------------------------------------------------------------
indexing.solr.docsChunkCommitImmediately=false

# ------------------------------------------------------------------------------------------------
# Flag indicating if the data must be pushed into Solr in parallel (true) or sequentially (false)
# Type of value: boolean
# Key is mandatory: No
# Default value: true
# ------------------------------------------------------------------------------------------------
indexing.solr.parallel=true

# ------------------------------------------------------------------------------------------------
# Flag influencing when Solr documents are committed (applies only when pushing data to Solr in parallel is enabled)
# If positive value is specified, the buffer of Solr documents (awaiting commit) is committed as soon as no additional data to process were found for the corresponding elapsed time.
# In other words, when they arrive, incoming data are converted to Solr format and accumulated into a buffer, but if no data comes for a certain period of time, the buffer is committed
# even if it has not reached the size specified in 'indexing.solr.docsChunkMaxWeightInMB' setting.
# A zero or negative value means unlimited (solr documents are never committed based on elapsed time but only when the buffer size corresponding to 'indexing.solr.docsChunkMaxWeightInMB' is reached)
# Note: if 'indexing.solr.docsChunkCommitImmediately' is set to 'true', this setting is ignored because Solr documents are not buffered but committed as soon as they are ready.
#
# Hint: this value may have a great influence on performance but its appropriate value is greatly dependent on other settings.
# As a rule of thumb, consider setting this value:
# - either to unlimited (0)
# - or to a value between 1 seconds (1000) and 1 minute (60000)
#
# Type of value: integer (in milliseconds)
# Key is mandatory: No
# Default value: 1000
# ------------------------------------------------------------------------------------------------
indexing.solr.parallel.pushers.autoCommitGracePeriodInMs=1000

# ------------------------------------------------------------------------------------------------
# Specify how many entries (from the pool of items to index) must be converted at once to Solr format (applies only when pushing data to Solr in parallel is enabled)
# A zero or negative value means unlimited (all the available items are taken and converted to Solr format)
#
# Hint: this value has a great influence on performance but its perfect value is greatly dependent on other settings.
# As a rule of thumb, consider setting this value:
# - either to unlimited (0)
# - or to a value similar to the 'indexing.processing.chunkSize' setting 
#
# Type of value: integer
# Key is mandatory: No
# Default value: 0 (unlimited value is highly recommended)
# ------------------------------------------------------------------------------------------------
indexing.solr.parallel.pushers.gobbetSize=0

# ------------------------------------------------------------------------------------------------
# Specify how many workers are allowed at most to concurrently push indexed data into Solr (applies only when pushing data to Solr in parallel is enabled)
# A zero or negative value means unlimited (a new worker is created as needed when all existing workers are busy)
# If positive, the value must be greater than 1 (so 2 and above) and greater or equal to the 'indexing.solr.parallel.initialParallelism' setting, otherwise an error will be raised.
#
# Hint: in normal conditions, even without any limitation, only a relative small number of workers (<15) are really needed
# to accomplish the task. However it could be already enough to put high pressure on the hardware or the network. So you may wish
# to define an hard upper limit with this setting.
#
# Type of value: integer
# Key is mandatory: No
# Default value: 0 (unlimited value is highly recommended)
# ------------------------------------------------------------------------------------------------
indexing.solr.parallel.maxParallelism=0

# ------------------------------------------------------------------------------------------------
# Specify how many workers created initially to push indexed data into Solr (applies only when pushing data to Solr in parallel is enabled)
# The value must be greater than 1 (so 2 and above) otherwise an error will be raised.
# The value cannot be smaller than the 'indexing.solr.parallel.maxParallelism' setting
#
# Type of value: integer (minimal value is 2)
# Key is mandatory: No
# Default value: 5
# ------------------------------------------------------------------------------------------------
indexing.solr.parallel.initialParallelism=5

# ------------------------------------------------------------------------------------------------
# The number of Rochade items that may be buffered, waiting for them to be pushed into Solr.
# When that buffer is full, the processing of Rochade items is paused until the buffer gets some room.
# This buffer is entirely in memory, so it has a direct impact on memory usage.
# A big value is required to avoid bottlenecks, but that value must be sized according to the memory allocated to the JVM
# as this buffer directly contributes (among others phenomenoms) to Out Of Memory exception if it grows excessively.
#
# Important: This value must be adapted according to the max available memory allocated to the application. The more memory, the bigger this value can be.
# However, regarding the performance, as soon as this value is big enough to avoid bottlenecks, the buffer will never get full and so it is useless
# to set it too high (it will not enhance the performance). If set too high it will uselessly requires extra memory.
# The default value is normally fine if other settings relative to the parallelism are correctly-sized.
# 
# Type of value: integer
# Key is mandatory: No (but highly recommended)
# Default value: 1 000 000
# ------------------------------------------------------------------------------------------------
indexing.solr.parallel.bufferSize=1000000

# ------------------------------------------------------------------------------------------------
# Determines the timeout in milliseconds until a connection to the Solr server is established.
# A timeout value of zero is interpreted as an infinite timeout. A negative value is interpreted as undefined (system default if applicable).
# Type of value: long
# Key is mandatory: No
# Default value: 15000 (15 seconds)
# ------------------------------------------------------------------------------------------------
solr.connectionTimeoutInMs=15000

# ------------------------------------------------------------------------------------------------
# Defines the socket timeout (SO_TIMEOUT) in milliseconds, which is the timeout for waiting for data or, put differently, a maximum period inactivity between two consecutive data packets).
# A timeout value of zero is interpreted as an infinite timeout. A negative value is interpreted as undefined (system default if applicable).
# Type of value: long
# Key is mandatory: No
# Default value: 120000 (120 seconds)
# ------------------------------------------------------------------------------------------------
solr.readTimeoutInMs=120000

# ------------------------------------------------------------------------------------------------
# Defines how many times a given Solr operation (commit, query, delete...) must be tried again when an I/O error occurs.
# If the operation succeeds during a retry, the indexing process continues as usual (the event is nevertheless logged at 'warning' level).
# However, if the operation still fails after the number of attempts specified by this setting, then a fatal error is reported,
# and the indexing process stops itself.
# Zero or negative value means: do not retry but fail immediately.
# Type of value: integer
# Key is mandatory: No
# Default value: 3
# ------------------------------------------------------------------------------------------------
indexing.solr.operations.nbRetries=3

# ------------------------------------------------------------------------------------------------
# Defines if read timeout must be raised each time a Solr operation (commit, query, delete...) is retried due to an I/O error.
# This setting applies only when 'indexing.solr.operations.nbRetries' setting is greater than 0.
# Type of value: boolean
# Key is mandatory: No
# Default value: true
# ------------------------------------------------------------------------------------------------
indexing.solr.operations.retryWithExtendedTimeout=true

# ------------------------------------------------------------------------------------------------
# Specify if evolution of memory usage must be logged regularly during the indexing process.
#
# Type of value: boolean
# Key is mandatory: No
# Default value: false
# ------------------------------------------------------------------------------------------------
debug.traceMemoryEvolution=false

# ------------------------------------------------------------------------------------------------
# Specify if statistics about retrieving data from Rochade must be collected during the indexing process and at which frequency.
# Following frequency can be specified:
# - Never (default value): no statistics are collected
# - PerQuery: statistics are collected each time Rochade server is queried (ultra verbose)
# - PerChunk: statistics are collected each time a chunk of items are indexed (see 'indexing.processing.chunkSize' for the chunk size)
# - PerType: statistics are collected each time a type is fully indexed
# - PerCore: statistics are collected each time a core/metaapp is fully indexed
#
# Type of value: enumeration
# Key is mandatory: No
# Default value: Never
# ------------------------------------------------------------------------------------------------
debug.rochade.statistics.byConnection.frequency=Never

# ------------------------------------------------------------------------------------------------
# Specify how the statistics about retrieving data from Rochade must be collected during the indexing process.
# Following mode can be specified:
# - Accumulate (default value): statistics are never reset for a given connection. It means that statistics report the average values during the whole execution of one indexing cycle. Statistics are nevertheless reset between two indexing cycles.
# - Fresh: statistics are cleared between each collect operation. It means that the statistics represent the average values of operations that happened only between two statistics collect operation.
#
# Type of value: enumeration
# Key is mandatory: No
# Default value: Accumulate
# ------------------------------------------------------------------------------------------------
debug.rochade.statistics.byConnection.mode=Accumulate

# ------------------------------------------------------------------------------------------------
# Specify if global statistics about Rochade server must be collected after each indexing cycle..
#
# Type of value: boolean
# Key is mandatory: No
# Default value: false
# ------------------------------------------------------------------------------------------------
debug.rochade.statistics.globally=false

# ------------------------------------------------------------------------------------------------
# Technologies
# Value: normalized technology name
# Type of value: String
# Key is "technology." prefix followed by the technology name or alias name in UPPER CASE
# technology name or alias name is searched case-insensitive and mapped to the normalized name
# If no mapping is found, a warning is issued and the name found is added to the internal mapping.
# ------------------------------------------------------------------------------------------------
technology.DB2=DB2
technology.DB2\ SQL\ MODULE=DB2
technology.DB2\ SQL\ TRIGGER=DB2
technology.DB2\ DATABASE=DB2
technology.DB2\ TABLE=DB2
technology.DB2\ USER=DB2
technology.DB2\ FIELD=DB2
technology.DB2/400\ SQL\ TRIGGER=DB2
technology.DB2/400\ SQL\ MODULE=DB2
technology.DB2/400\ TABLE=DB2
technology.DB2/400=DB2
technology.DB2400=DB2
technology.DB2/400\ CONSTRAINT=DB2
technology.DB2/400\ VIEW=DB2
technology.DB2/400\ SQL\ PL=DB2
technology.DB2/400\ INDEX=DB2
technology.UDB=DB2
technology.UDB\ SQL\ MODULE=DB2
technology.UDB\ SQL\ TRIGGER=DB2

technology.ORACLE=Oracle
technology.ORA=Oracle
technology.ORACLE\ SQL\ MODULE=Oracle

technology.SQL\ Server=SQL Server
technology.MS\ SQL\ Server=SQL Server
technology.MSSQLSERVER=SQL Server
technology.SQLSERVER=SQL Server
technology.SQL=SQL Server
technology.SQLSVR=SQL Server
technology.SQL\ SERVER\ SQL\ MODULE=SQL Server
technology.SQL\ SERVER\ SQL\ SCRIPT=SQL Server
technology.SQL\ SERVER\ SQL\ TRIGGER=SQL Server

technology.MYSQL=MySQL

technology.NETEZZA=Netezza

technology.TERADATA=Teradata
technology.TDATA=Teradata

technology.GREENPLUM=Greenplum
technology.SCANGREENPLUM=Greenplum
technology.SGP=Greenplum

technology.SYBASE/SAP\ ASE=Sybase/SAP ASE
technology.SYBASE=Sybase/SAP ASE

technology.COGNOS\ BI=Cognos BI
technology.SCANCOGNOS=Cognos BI
technology.COGNOS=Cognos BI

technology.BUSINESS\ OBJECTS=Business Objects
technology.BOXI\ SCANNER=Business Objects
technology.BOXI=Business Objects
technology.BO=Business Objects

technology.MICROSTRATEGY=MicroStrategy
technology.MICROSTRATEGY\ SCANNER=MicroStrategy
technology.SCANMCS=MicroStrategy
technology.MCS=MicroStrategy

technology.DATASTAGE=DataStage
technology.SCANDATASTAGE=DataStage

technology.INFORMATICA=Informatica
technology.SCANINFORMATICA=Informatica
technology.INFA=Informatica

technology.SSIS=SSIS
technology.SCANMSSIS=SSIS
technology.ScanMSS=SSIS

technology.SSAS=SSAS
technology.SCANMSSAS=SSAS

technology.SSRS=SSRS
technology.SCANMSSRS=SSRS

technology.TABLEAU=SCANNER\=Tableau
technology.TABLEAU=SCANNER\=Tableau

technology.ERWIN=ERwin
technology.ERW=ERwin

technology.BIGDATA=BigData
technology.BIG\ DATA=BigData

technology.CLOUDERA\ NAVIGATOR=Cloudera Navigator
technology.CNAVIGATOR=Cloudera Navigator

technology.CDAP=CDAP

technology.AZURE\ SQL\ DW=Azure SQL DW

technology.AZURE\ SQL\ DB=Azure SQL DB

technology.AZURE\ COSMOS=Azure Cosmos

technology.AVRO=Avro

technology.SNOWFLAKE=Snowflake

technology.AMAZON\ S3=Amazon S3

technology.AMAZON\ GLUE=Amazon Glue

technology.REDSHIFT\ SPECTRUM=Redshift Spectrum

technology.REDSHIFT=Redshift

technology.HIVE=Hive

technology.PYTHON=Python

technology.JAVA=Java

technology.MOBIUS=Mobius

technology.HDFS=HDFS
technology.HADOOP\ FILES=HDFS

technology.LOCAL\ FILES=Local Files

technology.GIT=Git

technology.PARQUET=Parquet

technology.HBASE=HBase

technology.GEMFIRE=Gemfire

technology.CASSANDRA=Cassandra

technology.POSTGRESQL=PostgreSQL

technology.MONGODB=MongoDB

technology.DYBAMODB=DynamoDB

technology.JSON=JSON

technology.BECUBIC\ SCANNER=Becubic Scanner
technology.BECUBIC=Becubic Scanner
